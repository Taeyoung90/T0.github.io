---

title: "[Pytorch] 파이토치 첫걸음을 공부하며2(합성곱신경망~)"
excerpt: "'파이토치 첫걸음'을 공부하며 정리한 내용 3"
last_modified_at: 2021-09-01

categories: 

 - Pytorch
 
tags:

 - Pytorch
 - AI
 - 필사

# header:
#   overlay_image: https://images.unsplash.com/photo-1501785888041-af3ef285b470?ixlib=rb-1.2.1&ixid=eyJhcHBfaWQiOjEyMDd9&auto=format&fit=crop&w=1350&q=80
#   overlay_filter: 0.5 # 투명도

toc: true
toc_icon: "bars" # 아이콘 설정
toc_sticky: true #목차를 스크롤과 내릴것인지
toc_label: "목차"
#색상 R:ff4c4c G:34bf49 B:0099e5
---

'파이토치 첫걸음'을 공부하며 2번째 포스팅  
합성곱 신경망 이어서... GoogLeNet부터...
현재 vision에 집중해서 빠르게 pytorch를 익히기 위해 중간에 RNN파트는 대충 훑어보고 따로 정리를 안함
- - -

## GoogLeNet
- 2014년 최고 성능
- 인셉션 모듈(Inception module)이라는 블록 있음 > Inception network
- 아래 그림의 (a)를 보면 3가지의 합성곱과 맥스 풀링을 하는데, 숲에서 나무를 찾는 것과 숲에서 나뭇잎을 찾는 것이 차이가 있듯이 서로 다른 크기의 특징을 추출하기 위함임
- (b)는 (a)의 메모리를 많이 사용하는 문제를 해결하고자 한 것
<p align="center">
<img src="https://user-images.githubusercontent.com/73866596/131492393-db53aa2e-d8e7-44d1-a27e-27e0937773bd.png" width='500px'><br/>
<em>출처: '파이토치 첫걸음'</em>
</p>

- $1\times1$ 합성곱은 가로세로기준으로는 크기변화가 없지만, 채널입장에서는 아래 그림처럼 입력 채널수만큼 입력받고 출력 채널수를 생성함 > 즉, map의 크기 변화는 없지만 채널을 변경할 수 있음
<p align='center'>
<img src="https://user-images.githubusercontent.com/73866596/131522212-cb1b4e82-7d4f-4651-8a73-9a25ebecb875.png"><br/>
<em>출처: '파이토치 첫걸음'</em>
</p>

- 채널 입장에서는 아래 그림처럼 완전연결 네트워크라고 볼 수 있음

<p align='center'>
<img src="https://user-images.githubusercontent.com/73866596/131522251-4930607a-1d8b-4d40-ab36-75e95832a3d4.png" width="400px"><br/>
<em>출처: '파이토치 첫걸음'</em>
</p>

- 이처럼 채널을 바꿀 수 있기에, 채널 수를 감소시키면(ex. 128 > 32) 입력 텐서를 채널방향으로 압축할 수 있음  
기초적인 인셉션 모듈(a)가 128 > 256 채널로 증가시키는 연산이라면, (b)는 128 > 32 채널로 줄이고 다시 합성곱을 통해 256개로 늘림  
→ 기존보다 연산량 감소하여 메모리 사용 줄임

- 구글넷 중간중간에 **보조 분류기(auxiliary classifier)가** 있는데 모델이 깊어지면서 발생한 손실이 입력층까지 잘 전달이 안되는 현상을 극복하기 위해 사용됨(학습시에만 사용)


<p align='center'>
<img src="https://user-images.githubusercontent.com/73866596/131530287-018cbb12-1d0c-48bd-aa8f-8b01a6790dda.png" ><br/>
<em>출처: '파이토치 첫걸음'</em>
</p>


## 전이학습(Transfer Learning)

- 전이학습은 다른 task로 학습을 한 지식(모델)을 다른 task에 활용하는 학습방법
- pytorch에는 이미 학습된 모델이 많이 있음
- 이미지넷으로 학습된 resnet 불러오기

```ruby
import torchvision.models as models
resnet = models.resnet50(pretrained=True)
```

```ruby
#resnet모델의 직속 child node
for name, module in resnet.named_children():
  print(module)# 레이어 확인
```

<p align="center">
<img src='https://user-images.githubusercontent.com/73866596/131700645-cba0dc83-a296-402a-b1fa-48749ca3ec99.png'><br/>
</p>

```ruby
import torch
import torch.nn as nn

class Resnet(nn.Module):
  def __init__(self):
    super(Resnet, self).__init__()
    self.layer0 = nn.Sequential(*list(resnet.children())[0:-1]) #resnet.children()은 학습된 모듈의 변수들이 포함되어 있고 이를 list로 만들고나서 *로 언패킹함, 마지막 fc layer는 제외
    self.layer1 = nn.Sequential(
        nn.Linear(2048, 500),
        nn.BatchNorm1d(500),
        nn.ReLU(),
        nn.Linear(500,num_category),
        nn.ReLU()
    )

  def forward(self,x):
    out = self.layer0(x)
    out = out.view(batch_size,-1) #4d tensor > 2d tensor
    out = self.layer1(out)
    return out
```

- pretrained layer는 freezing(학습 안함), 새로 추가한 layer만 학습하도록 설정

```ruby
#학습의 대상이 되는 변수 범위를 정하기
for params in model.layer0.parameters(): # layer0(pretrained) 학습 안함(freezing)
  params.require_grad = False #해당 레이어의 파라미터들은 기울기 계산 x > 업데이트 X

for params in model.layer1.parameters(): # layer1(new)만 학습
  params.requires_grad = True
```

## 스타일 트랜스퍼
- 스타일 트랜스퍼는 전이학습의 단적인 예
- 스타일 트랜스퍼에서 사용한 모델은 주로 imagenet classification에 사용된 모델  
이 모델들은 공통적으로 이미지에서 특정한 형태(feature)를 구분할 수 있는 필터를 갖고 있음(이미지의 representation을 잘 학습)
- 입력단에 가까운 레이어들은 가로선, 세로선, 대각선, 색에 반응하는 등 간단한 특징을 학습하는 필터  
레이어가 깊어질수록 앞의 간단한 필터들의 조합으로 복잡한 형태를 구분함
- 이러한 필터(가로,세로, 대각선등)는 task와 상관없이 물체를 인식하는데 모두 적용 가능  
→ **범용성 Good!!**

<p align='center'>
<img src="https://user-images.githubusercontent.com/73866596/131703704-a0ef03f9-dc15-4764-bfe9-9bcbe96e517e.png"><br/>
<em>출처 : Visualizing and Understanding Convolutional Networks</em>
</p>