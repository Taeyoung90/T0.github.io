---

title: "[논문 리뷰] YOLOv3: An Incremental Improvement(YOLO v3)"
excerpt: "YOLO v3 논문 리뷰"
last_modified_at: 2021-08-24

categories: 

 - 논문리뷰
 
tags:

 - YOLO
 - AI
 - 논문리뷰
 - VISION

# header:
#   overlay_image: https://images.unsplash.com/photo-1501785888041-af3ef285b470?ixlib=rb-1.2.1&ixid=eyJhcHBfaWQiOjEyMDd9&auto=format&fit=crop&w=1350&q=80
#   overlay_filter: 0.5 # 투명도

toc: true
toc_icon: "bars" # 아이콘 설정
toc_sticky: true #목차를 스크롤과 내릴것인지
toc_label: "목차"
#색상 R:ff4c4c G:34bf49 B:0099e5
---
YOLO v3 논문([YOLOv3: An Incremental Improvement](https://arxiv.org/pdf/1804.02767.pdf))을 읽고 정리해 본다.  
YOLO v3 논문은 technical report로 일반적인 논문보다 compact하게 작성되어 분량이 적다.  
<br/>
## Abstract
- 이전 yolo보다 size 증가 → more accurate, still fast
<br/>

# 1 Introduction
tech report라 별 내용 없음

# 2 The Deal
- 다른 사람들로부터 좋은 아이디어 차용  
- 성능이 가장 좋은 건 아니지만 속도는 매우 빠름  

<p align="center"><img src="https://user-images.githubusercontent.com/73866596/130476829-96a043d8-58c7-440c-a960-f163aacebc6f.png" width="450px"></p>  

## 2.1 Bounding Box Prediction
- Dimension clustering을 통해 anchor box를 생성하여 bbox예측
- bbox는 SSE(sum of squared error) loss 사용
- logistic regression으로 bbox의 objectness score 예측  
    * GT(Gound Truth)와 가장 많이 겹치는 bbox가 1, threshold(0.5)보다 크지만 best가 아니면 무시  

<p align="center"><img src="https://user-images.githubusercontent.com/73866596/130477413-77615027-73d3-436b-8193-01e7870dadd4.png" width="400px"></p>  

## 2.2 Class Prediction
- Multilabel classification을 통해 각 box는 bbox가 포함할 수 있는 class들을 예측
- Softmax 사용 하지 않음 → logistic classifer 사용(성능 때문에)
- class prediction을 위해 binary cross entropy loss 사용하여 훈련  
> 이러한 과정은 복잡한 도메인 적용에 도움이 됨  
> Overlapping data(ex. person이면서 woman인 경우와 같이)에서 softmax를 쓰면 box당 하나의 class라고 가정해버리는셈이서 여러 class prediction 못함

## 2.3 Prediction Across Scales
- YOLO v3는 3가지 scale에서 예측
- 3가지 scale로부터 feature 추출(feature pyramid network와 비슷)  
<span style="color:#34bf49">feature pyramid network</span>는 추후 공부
- 3d tensor형태의 bbox, objectness, class prediction 예측
- 각 scale 별로 3개 box 예측 : N × N × [3 * (4+1+80)]  
(3개 box, 4개의 coordinates offset, 1 objectness, 80개 class(COCO dataset))  
- <span style="color:#ff4c4c"> 이전 2개 layer로 부터 얻은 feature map을 2배 upsampling, 앞의 network에서 얻은 feature map과 merge(concatenation)</span>
→ 이를 통해서 의미정보(upsampled feature)와 세부적인 정보(앞단의 feature map)을 모두 활용  

**이 부분은 아직 덜 이해되서 추후 다시 정리 함!!**

- bbox prior를 k-means clustering으로 정함  
→ 9개의 클러스터와 임의의 3개 scale에 대해서, scale에 따라 균등하게 clsuter를   
(여기서는 (10×13) (16×30) (33×23) (30×61) (62×45) (59×119) (116 × 90) (156 × 198) (373 × 326))

## 2.4 Feature Extractor
- YOLO v2의 상단 network에 새로운 residual network를 더함
- 3×3, 1×1 conv. layer를 연속적으로 사용하고 shortcut connection도 있음(충분히 크고)  > Darknet 53이라 칭함  
<span style="color:#34bf49"> \* shortcut connection에 대해서도 추후 공부</span>

<p align="center"><img src="https://user-images.githubusercontent.com/73866596/130477616-389c023d-5624-47f0-9d99-6a5f35761b63.png" width="450px"></p>  
- 이전의 Darknet 19보다 powerful, ResNet 101, ResNet 152보다 efficient
- 256 × 256(single crop)에서 훈련 및 테스트
- ResNet은 레이어가 너무 많고 비효율적

## 2.5 Training
- negative mining이나 다른 방법없이 full image 사용
- multi-scale training, data augmentation, batch norm. 등 일반적인 방법들 사용

# 3 How We Do
- SSD 기반 모델들과 비슷한 mAP이지만 3배 빠름
- RetinaNet보다는 성능이 뒤쳐짐
- 'old' detection metric인 mAP at IOU=50에서 강력함 → object에 대한 box 잘 찾음  
but IOU threshold 증가할수록 성능 급격히 감소
- 과거의 YOLO는 small object에 약했지만, multi-scale prediction을 사용한 v3는 small보다는 medium과 large size에서 상대적으로 성능이 떨어짐

# 4 Things We Tried That Didn't Work
여러가지 시도해 봤지만 의미가 없었던 작업들 나열
- **anchor box x,y offset 예측** : linear activation으로 w, h 를 예측한 것처럼 일반적인 anchor box 예측 메커니즘으로 x,y offset도 예측 시도  
→ model의 stability <br/>

- **logistic 대신 linear x,y 예측** : x,y 예측을 위해 linear activation으로 다이렉트 예측 시도  
→ 오히려 mAP 감소 <br/>

- **Focal loss** : focal loss 사용 시도  
→ 오히려 mAP 감소  
(YOLO v3는 이미 focal loss problem에 rubust, objectness와 conditional class prediction을 분리하기 때문에)  
<span style="color:#34bf49"> \* focal loss에 대해서 추후 공부</span> <br/>

- **Dual IOU threshold and truth assignment** : Faster R-CNN은 훈련동안 2개의 IOU threshold 사용  
(0.7이상은 positive sample, 0.3이하는 negative > 무시)  
→ 시도했지만 not good

# 5 What This All Means
- YOLO v3는 fast, accurate, but 0.5~0.95 mAP(COCO)에서는 그리 좋지 않음(old metric인 0.5에서는 좋음)  
- 이런 것보다 기술 연구에 대해서 윤리적 책임에 대해 생각해 볼 것을 권유
- - -
현재는 VISION분야의 trend를 좇기 위해서 빠르게 훑는 데에 집중하고 추후 다시 세세하게 파악해야 함