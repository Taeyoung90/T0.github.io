---

title: "[Pytorch] 파이토치 첫걸음을 공부하며2(합성곱신경망~)"
excerpt: "'파이토치 첫걸음'을 공부하며 정리한 내용 2"
last_modified_at: 2021-08-29

categories: 

 - Pytorch
 
tags:

 - Pytorch
 - AI
 - 필사

# header:
#   overlay_image: https://images.unsplash.com/photo-1501785888041-af3ef285b470?ixlib=rb-1.2.1&ixid=eyJhcHBfaWQiOjEyMDd9&auto=format&fit=crop&w=1350&q=80
#   overlay_filter: 0.5 # 투명도

toc: true
toc_icon: "bars" # 아이콘 설정
toc_sticky: true #목차를 스크롤과 내릴것인지
toc_label: "목차"
#색상 R:ff4c4c G:34bf49 B:0099e5
---

'파이토치 첫걸음'을 공부하며 2번째 포스팅  
합성곱 신경망 이어서... VGG 모델 구현까지
- - -

### Cross-entropy

엔트로피는 불확실성을 뜻함 > 불확실할수록 커짐  
- ex) 가방 안에 빨간공만 있으면 entropy =0 > 무조건 빨간 공 > 불확실성 없음  
사건이 같은 비율로 발생할 때, 사건의 개수를 n이라고 하면 $entropy = log(n)$  
빨간공: 녹색공 = 50: 50비율이면 $entropy = log_2(2)=1$  
→ 직관적으로, 공을 꺼낼 때 반반으로 들어있으면, 어떤 공이 더 자주 관찰될지 예측할 수 없음 > entopy가 크다고 이해  
- 엔트로피  : p(x)가 일어날 확률이 낮음 > 작은 값 > $-\log p(x)$ 커짐<br/>
$$H(p) = -\sum_x  p(x)\log p(x)$$  

- 크로스엔트로피<br/>
$$H(p,q) = -\sum_x p(x)\log q(x)$$
- 목표로 하는 최적의 확률분포 p, 이를 근사하려는 확률분포 q가 얼마나 다른지 측정하는 방법  
→ 원래 p였던 분포를 q로 표현했을 때 얼마만큼의 비용이 드는지를 측정한다고 이해  
ex) 동전던지기는 최적확률은 앞 $\frac{1}{2}$ 뒤 $\frac{1}{2}$이기 때문에 엔트로피는  
$$H(x) = 0.5 \times (-\log_2 \frac{1}{2}) + 0.5(-\log_2 \frac{1}{2}) = 1 이지만$$  

- 만약 누군가 앞 $\frac{1}{4}$ 뒤 $\frac{3}{4}$라고 예측했다면,  
$$H(x) = 0.5 \times (-\log_2 \frac{1}{4}) + 0.5(-\log_2 \frac{3}{4}) = 1.2075 가 됨 $$
- 보면 최적확률일 때보다 엔트로피가 증가했음 > 더 큰 비용(손실)

- 즉 교차 엔트로피는 최적분포p의 엔트로피에 KLD(쿨백-라이블러 발산, Kullback-Leibler divergence)항을 더한 것  
p를 기준으로 q가 얼마나 다른지를 측정하는 방법  
따라서 **교차 엔트로피를 최소화**한다는 것은 > **p의 엔트로피는 고정값**이므로 **KLD를 최소화**시켜  q를 p 분포와 최대한 같게 함을 의미

$$\begin{aligned}
H(p,q) &= H(p) + \sum_x p(x) \log \frac{p(x)}{q(x)}\\
&= H(p) + D_{KL}(p||q)
\end{aligned}$$

- ex) 강아지와 고양이 판별  
1) softmax 결과 : [강, 고] = [0.1,0.9] 일 때,  
$크로스엔트로피 = -(0 \ times \log_e 0.1 + 1 \times \log_e 0.9) = 0.1053$  
$L1loss  = |1-0.9| = 0.1 (고양이에 대해)$  
→ 큰 차이 없음
2) softmax 결과 : [0.7, 0.3] 일 때,  
$크로스엔트로피 = -(0 \ times \log_e 0.7 + 1 \times \log_e 0.3) = 1.2039$  
$L1loss  = |1-0.3| = 0.7 (고양이에 대해)$  
→ 크로스엔트로피가 훨씬 더 큼
* 이처럼 잘못 예측했을 때일수록 cross entropy가 L1 loss보다 크게 증가  
→ 그만큼 더 큰 패널(손실)  
→ 잘못된 예측에 대해 더 학습 잘됨  
→ 분류에서 교차 엔트로피를 많이 사용하는 이유

### 모델구현, 학습 및 결과 확인
MNIST 데이터로 간단한 CNN 모델을 만들고 성능 확인해보자
- DataLoader : 효율적인 학습에 따라 데이터를 어떤 규칙에 따라 정렬하거나 섞거나 해주는 역할  
- torchvision : 유명한 영상처리용 데이터셋, 모델, 이미지 변환기가 들어있는 패키지

```ruby
import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.init as init
import torchvision.datasets as dset
import torchvision.transforms as transforms
from torch.utils.data import DataLoader

batch_size = 256
learning_rate = 0.0002
num_epoch = 10
```
- transforms.ToTensor() : 이미지를 파이토치 텐서로 변환  
- DataLoader의 num_workers : 데이터를 묶을 때 사용할 프로세스 개수  
\* num_workers는 몇 개가 적당한지에 대한 정답은 없다고 함. 학습 환경의 GPU, CPU개수, I/O속도, 메모리 등과 같이 다양한 조건에 따라 최적의 값이 다르다고 함(참고 : https://cvml.tistory.com/24)
- drop_last : 데이터를 batch_size만큼 묶고 나머지를 버릴지 여부

```ruby
mnist_train = dset.MNIST('./', train=True, transform=transforms.ToTensor(), target_transform=None, download=True)
mnist_test = dset.MNIST('./',train=False, transform=transforms.ToTensor(), target_transform=None, download=True)

train_loader = torch.utils.data.DataLoader(mnist_train, batch_size=batch_size, shuffle=True, num_workers=2, drop_last=True)
test_loader = torch.utils.data.DataLoader(mnist_test, batch_size=batch_size, shuffle=True, num_workers=2, drop_last=True)
```
- 모델 생성
- tensor.view(batch_size, -1) 은 크기를 $batch_size \times ?$로 바꾸라는 의미, -1은 나머지는 알아서 계산하라는 의미 여기서는 뒤에 있는 64,3,3을 곱하게 됨 
- class형태 모델은 항상 `nn.Module`을 상속받아야 하고, `super(모델명, self).__init__()`을 통해 `nn.Module.__init__()`을 실행시키는 코드가 필요

```ruby
class CNN(nn.Module):
  def __init__(self): #nn.Module 초기화 역할
    super(CNN, self).__init__()
    self.layer = nn.Sequential(
        nn.Conv2d(1,16,5), #[batch_size,1,28,28] > [batch_size,16,24,24]
        nn.ReLU(),
        nn.Conv2d(16,32,5),#[batch_size,16,24,24] > [batch_size,32,20,20]
        nn.ReLU(),
        nn.MaxPool2d(2,2),#[batch_size,32,20,20] > [batch_size,32,10,10]
        nn.Conv2d(32,64,5),#[batch_size,32,10,10] > [batch_size,64,6,6]
        nn.ReLU(),
        nn.MaxPool2d(2,2)#[batch_size,64,6,6] > [batch_size,64,3,3]
    )
    self.fc_layer =nn.Sequential(
        nn.Linear(64*3*3,100),#[64*3*3] >[100]
        nn.ReLU(),
        nn.Linear(100,10)# [100] > [10]
    )
  
  def forward(self, x): #순차적으로 실행
    out = self.layer(x) #layer에 x를 넣고 나온 출력 값 = out [10]
    out = out.view(batch_size,-1) #[batch_size, -1]형태를 전달, -1은 알아서 계산 > batch_size뒤의 3개 인수 64,3,3을 곱해서 하나로 만됨
    out = self.fc_layer(out)
    return out
```

- 훈련

```ruby
loss_arr=[]
for i in range(num_epoch):
  for j, [image,label] in enumerate(train_loader):
    x = image.to(device)# 이미지 데이터 device에 얹고
    y_ = label.to(device)# 라벨도 device에 얹고

    optimizer.zero_grad()#초기화
    output = model.forward(x) #순차적 실행
    loss = loss_func(output,y_)
    loss.backward() #기울기 계산, 역전파
    optimizer.step() #업데이트

    if j %1000 ==0:
      print(loss)
      loss_arr.append(loss.cpu().detach().numpy())
```

- 테스트
- label.size() > torch.Size([256])이므로 0값을 넣으면 256이 나옴(batch_size)


```ruby
correct = 0 #맞은 개수 초기화
total = 0 #전체 개수 초기화

with torch.no_grad(): #테스트 모드이기 때문에 기울기 계산 안함
  for image, label in test_loader:
    x= image.to(device)
    y_ = label.to(device)

    output = model.forward(x)
    _, output_index = torch.max(output,1) #최대값(예측값이 가장 큰 값)과 인덱스(해당라벨) 반환

    total += label.size(0) #label.size의  0번째는 batch_size의미
    correct += (output_index == y_).sum().float() #output_index와 y_(라벨)같은면 1아니면 0인데 batch_size에 대해서 모두 1,0변환하고 sum하면 결국 맞는것 개수와 동일

  print('accuracy of test data: {}'.format(100*correct/total))
```
<br/>
## VGGNet
- $3 \times 3$ conv layer, maxpooling, fc layer  3가지로만 구성
- 2014년 대회에서 2위(GoogLeNet 1위)
### 단순 코드 구현
- VGG 모델중 하나(conv 2번 반복 2개, 3번 반복 3개) 구현
- 하지만 아래와 같은 방식은 레이어가 다른 모델을 구현할 때 많은 수정이 필요함

```ruby
def conv_2_block(in_dim, out_dim):
  model = nn.Sequential(
      nn.Conv2d(in_dim, out_dim, kernel_size=3, padding=3),
      nn.ReLU(),
      nn.Conv2d(out_dim,out_dim, kernel_size=3,padding=1),
      nn.ReLU(),
      nn.MaxPool2d(2,2)
  )
  return model

def conv_3_block(in_dim,out_dim):
  model = nn.Sequential(
      nn.Conv2d(in_dim,out_dim,kernel_size=3,padding=1),
      nn.ReLU(),
      nn.Conv2d(out_dim,out_dim,kernel_size=3,padding=1),
      nn.ReLU(),
      nn.Conv2d(out_dim,out_dim,kernel_size=3,padding=1),
      nn.ReLU(),
      nn.MaxPool2d(2,2)
  )
  return model
```

```ruby
class VGG(nn.Module):
  def __init__(self, base_dim, num_classes=2):
    super(VGG, self).__init__()
    self.feature = nn.Sequential(
        conv_2_block(3, base_dim),
        conv_2_block(base_dim, 2*base_dim),
        conv_3_block(2*base_dim, 4*base_dim),
        conv_3_block(4*base_dim, 8*base_dim),
        conv_3_block(8*base_dim, 8*base_dim),
    )
    self.fc_layer = nn.Sequential(
        nn.Linear(8*base_dim*7*7, 100),
        nn.ReLU(True),
        nn.Linear(100,20),
        nn.ReLU(True),
        nn.Linear(20, num_classes),
    )

  def forward(self, x):
    x =self.feature(x)
    x = x.view(x.size(0), -1)
    x= self.fc_layer(x)
    return x
```

### 파이토치 공식 구현 버전
- `features`에 들어가는 모델을 `make_layers`라는 함수로 생성
- 모델 구조를 cfgs에 미리 정의함(쉽게 모델 추가 가능)  
숫자는 필터수, 'M'은 맥스풀링 의미

```ruby
class VGG(nn.Module):

  def __init__(self, features, num_classes=1000, init_weights=True):
    super(VGG,self).__init__()
    self.features= features
    self.avgpool = nn.AdaptiveAvgPool2d((7,7))
    self.classifier = nn.Sequential(
        nn.Linear(512*7*7, 4096),
        nn.ReLU(True),
        nn.Linear(4096, 4096),
        nn.ReLU(True),
        nn.Linear(4096, num_classes),
    )
    if init_weights:
      self._initialize_weights()

  def forward(self, x):
    x= self.features(x)
    x= self.avgpool(x)
    x = x.view(x.size(0), -1)
    x =self.classifier(x)

  def _initialize_weights(self):
    for m in self.modules():
      if isinstance(m, nn.Conv2d):
        nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')
        if m.bias is not None:
          nn.init.constant_(m.bias, 0)
      elif isinstance(m, nn.BatchNorm2d):
        nn.init.constant_(m.weight, 1)
        nn.init.constant_(m.bias, 0)
      elif isinstance(m, nn.Linear):
        nn.init.normal_(m.weight, 0, 0.01)
        nn.init.constant_(m.bias, 0)

  def make_layers(cfg, batch_norm=False):
    layers= [] # 빈리스트 생성
    in_channels=3
    for v in cfg:
      if v == 'M': # cfg요소가 M 이면 maxpooling 추가
        layers += [nn.MaxPool2d(kernel_size=2, stride=2)]
      else:
        conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)
        if batch_norm:
          layers+= [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]
        else:
          layers += [conv2d, nn.ReLU(inplace=True)]
        in_channels = v
    return nn.Sequential(*layers) # *는 layers리스트의 요소를 모두 꺼냄을 의미, 모두 꺼내서 nn.Sequential로 감싸줌

  cfgs = {
      'A': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],
      'B': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],
      'D': [64, 64, 'M', 128, 128, 'M', 256, 256,256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],
      'E': [64, 64, 'M', 128, 128, 'M', 256, 256, 256,256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'] 
  }
```

* * *
VGGNET 모델 구현을 따라해봤는데, 언뜻보면 단순 구현이 직관적이엇 쉬워보이지만 , 모델의 layer를 변화시키면서 다양한 시도해보는 입장에서는 확실히 파이토치 공식 구현같이 layer생성을 함수화하여 구현하는게 좋을 것 같다

* * *

## 참고
- https://cvml.tistory.com/24
- https://medium.com/@inmoonlight/pytorch%EB%A1%9C-%EB%94%A5%EB%9F%AC%EB%8B%9D%ED%95%98%EA%B8%B0-intro-afd9c67404c3